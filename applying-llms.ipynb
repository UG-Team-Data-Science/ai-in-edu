{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7472d0-1c84-40a6-bba6-71474a062a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "model = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b9c781-2cb8-495d-a3bf-fe94c6a8e11c",
   "metadata": {},
   "source": [
    "### Acknowledgement\n",
    "\n",
    "Structuring bibliographical entries task taken from the excellent [marginalia project](https://github.com/Pleias/marginalia/tree/main)'s example notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997be4b8-9958-48bd-9d4a-cd35f94ff5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_history(message, history, system_prompt):\n",
    "    chat_history = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for query, response in history:\n",
    "        chat_history.append({\"role\": \"user\", \"content\": query})\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "    chat_history.append({\"role\": \"user\", \"content\": message})\n",
    "    return chat_history\n",
    "\n",
    "\n",
    "def prompt_model(message, history=None, system_prompt=\"You are a helpful assistant.\"):\n",
    "    chat_history = format_history(message, history if history else [], system_prompt)\n",
    "    response = client.chat.completions.create(model=model, messages=chat_history)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26bfa0a-904b-4712-892a-05f781fa8e68",
   "metadata": {},
   "source": [
    "## Zero-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc790f3-7b51-4a15-b407-c3f1c5747f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Transform this a book entry into structured bibliographic data\n",
    "\n",
    "Extract the following bibliographic fields:\n",
    "- the author(s) of the book, which can be expressed with a possessive like Hobbes's (\"author\")\n",
    "- the title of the book (\"title\")\n",
    "- the translator(s) of the book (\"translator\")\n",
    "- the date of publication (\"date\")\n",
    "- the place of publication (\"place\")\n",
    "- any information related to the format such as volumes, folios (\"format\") \n",
    "- any other information related to the book (\"other\")\n",
    "\n",
    "Return the results as a valid JSON object structured like this : {\"author\": \"…\", \"title\": \"…\", \"translator\": \"…\", \"date\": \"…\", \"place\": \"…\", \"format\": \"…\", \"other\": \"…\"}\n",
    "\n",
    "The book entry:\n",
    "```\n",
    "FINE large Folio BIBLE, compleat, Oxford 1727.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "print(\n",
    "    prompt_model(\n",
    "        prompt, system_prompt=\"You are a powerful annotator of bibliographic data\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c4aa20-58e7-4661-841b-3542dd540dc4",
   "metadata": {},
   "source": [
    "## Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6db63-9da1-4490-a5b6-17232eafafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_answer = \"\"\"\n",
    "Here is the extracted bibliographic data in JSON format:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"author\": null,\n",
    "  \"title\": \"BIBLE\",\n",
    "  \"translator\": null,\n",
    "  \"date\": \"1727\",\n",
    "  \"place\": \"Oxford\",\n",
    "  \"format\": \"Folio\",\n",
    "  \"other\": \"compleat\"\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "rebellion_question = \"\"\"\n",
    "Another book entry:\n",
    "```\n",
    "Clarendon's History of the Rebellion, 3 Vol\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = \"You are a powerful annotator of bibliographic data\"\n",
    "\n",
    "history = [\n",
    "    (intial_prompt, good_answer),\n",
    "]\n",
    "\n",
    "print(prompt_model(rebellion_question, history, system_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b2ae5-5b36-4c2d-a011-5891e73a4d63",
   "metadata": {},
   "source": [
    "**Exercise** Use \"History of the Rebellion\" as a few-shot example as well by defining the `rebellion_answer` variable in the cell below. Then try to analyze book entry \"Wiquefort's compleat Ambassador, translated by Digby, finely bound.\" by defining `ambassador_question`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2fd16-cbf1-41c3-afe7-42b994a2e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebellion_answer = \"\"\"\n",
    "<your answer here>\n",
    "\"\"\"\n",
    "\n",
    "ambassador_question = \"\"\"\n",
    "<your question regarding 'Wiquefort's compleat Ambassador, translated by Digby, finely bound.' here>\n",
    "\"\"\"\n",
    "\n",
    "history = [(prompt, good_answer), (rebellion_question, rebellion_answer)]\n",
    "\n",
    "prompt_model(ambassador_question, history, system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e03154-f8d4-4560-b750-3b1fc0a91d77",
   "metadata": {},
   "source": [
    "**Exercise** Add a final example by defining `ambassador_answer` in the cell below. Test your prompt on the entry \"Hobbes's Leviathan, very scarce.\" by defining `new_question`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d9d64-afe5-44d8-8ff1-1da8fedfd87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambassador_answer = \"\"\"\n",
    "<your answer regarding \"Wiquefort's compleat Ambassador, translated by Digby, finely bound.\" here>\n",
    "\"\"\"\n",
    "\n",
    "new_question = \"\"\"\n",
    "<your question regarding \"Hobbes's Leviathan, very scarce.\" here>\n",
    "\"\"\"\n",
    "\n",
    "history = [\n",
    "    (prompt, good_answer),\n",
    "    (rebellion_question, rebellion_answer),\n",
    "    (ambassador_question, ambassador_answer),\n",
    "]\n",
    "\n",
    "prompt_model(new_question, history, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ea1ec-bba5-4597-8b97-8cf8ab0c3cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
